{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2QWFcuGBRnf"
      },
      "source": [
        "[<img src=\"https://www.scenerepresentations.org/assets/logo/logo+text-negative@2x.png\" alt=\"TODO: make logo work better on Colab background\" width=\"212\"/>](https://www.scenerepresentations.org)\n",
        "\n",
        "[`MIT 6.S980, Machine Learning for Inverse Graphics`](https://www.scenerepresentations.org/courses/inverse-graphics/), Prof. Vincent Sitzmann\n",
        "# Optional PyTorch Intro\n",
        "\n",
        "**There is nothing in this notebook you will be graded on. If you are already a PyTorch expert (and you already know einsum), feel free to skip to the homework.**\n",
        "\n",
        "### Contributors\n",
        "- _Prof. Vincent Sitzmann, Scene Representation Group_\n",
        "- _Prafull Sharma_\n",
        "- _Ludwig Schubert_\n",
        "- _David Charatan_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re-9L-371oe6"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwg1s-Qaarre",
        "outputId": "30394eb4-405b-46a2-8fb8-e11312e54efe"
      },
      "outputs": [],
      "source": [
        "!pip install einops\n",
        "from einops import einsum\n",
        "\n",
        "# Visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# To make code more readable: some helpful Python 3 type hints\n",
        "from typing import Callable, List, Optional, Tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqTEiSuTje0U"
      },
      "source": [
        "PyTorch is an open-source machine learning framework. It's a package that offers convenient functions to perform GPU-accelerated computations with vectors and matrices and is the de-facto standard (together with JAX) for machine learning research.\n",
        "\n",
        "Outside of Google colab, you can install it by following the instructions [here](https://pytorch.org/get-started/locally/).\n",
        "\n",
        "Colab comes equipped with PyTorch. Let's import it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VicyqAGCZsW",
        "outputId": "f52a6bc1-cb7a-43dd-8e17-9f01e12e68e7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(f\"Installed Torch version: {torch.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE_JGy4gji8I"
      },
      "source": [
        "## Vectors & Matrices\n",
        "Vectors and matrices are represented as `torch.Tensor` types. A `torch.Tensor` is very similar to a numpy array. Here is an example of a vector $x \\in \\mathbb{R}^3$ and a matrix $A \\in \\mathbb{R}^{3 \\times 3}$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdWfL9iCjiKX",
        "outputId": "9d54cc36-a587-4079-f0e6-13b12428f53b"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor([1, 2, 3])\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHtsWRmIXHOs"
      },
      "source": [
        "The python class is called `torch.Tensor` (note capital \"T\"), but to initialize one from existing data we use the constructor function `torch.tensor`.\n",
        "\n",
        "We will often print a tensor's shape in these homework notebooks. We do this so the information is saved after running the notebook — when you are developing your own code, note that you can just hover over an instantiated tensor in Colab to show its shape! There's also a visual \"Variable inspector\", click the \"{x}\" button on the left toolbar, or open the command palette (⌘/Ctrl⇧P) and search for \"Show variable Inspector\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CiFXaUCkxzY",
        "outputId": "29c5d7b7-e5ab-4d24-eaba-8e2a2ba3e3e9"
      },
      "outputs": [],
      "source": [
        "A = torch.tensor([[1, 2, 3],\n",
        "                  [4, 5, 6],\n",
        "                  [7, 8, 9]])\n",
        "print(A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8ziMuY_AOR8"
      },
      "source": [
        "You can easily convert torch tensors to numpy arrays by calling `.numpy()` on them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HY_Ep8HASwH",
        "outputId": "a6736537-a9fe-4b0e-94b7-9038c5e80cbc"
      },
      "outputs": [],
      "source": [
        "A.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XS-UujGCt9X"
      },
      "source": [
        "As seen above, you can easily create PyTorch tensors from NumPy arrays or Python lists by simply calling the torch.Tensor() constructor on them. Other useful constructors that all take the *shape* of the tensor as parameter are:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrdwESWXC3YO"
      },
      "outputs": [],
      "source": [
        "shape = (5, 5)\n",
        "t0 = torch.zeros(shape) # tensor filled with zeros\n",
        "t1 = torch.ones(shape)  # tensor filled with ones\n",
        "tN = torch.randn(shape) # tensor values drawn from the standard normal distribution N(0,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "6GLDoGieGhcb",
        "outputId": "b43f7832-cff7-47eb-82ee-386d772a9641"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 3)\n",
        "for t, name, axis in zip((t0, t1, tN), ('torch.zeros', 'torch.ones', 'torch.randn'), axes):\n",
        "    axis.set_title(name)\n",
        "    axis.imshow(t, vmin=0, vmax=1, cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6FiIZZsAWec"
      },
      "source": [
        "Just like numpy arrays, Torch tensors can have different data types. The most common ones are floating point numbers (`float32`) and signed integers (`int`). A tensor's data type is accessible via the `dtype` property like in numpy. You can easily explicitly cast tensors to a different data type by calling `.float()` or `.int()` on them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omz1-BlyJzyy",
        "outputId": "a7e6fa81-d185-4c28-f430-297f8fe87199"
      },
      "outputs": [],
      "source": [
        "A.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhCqjaJZAsAt",
        "outputId": "54412973-d8a9-4eb7-9607-358d858c5154"
      },
      "outputs": [],
      "source": [
        "A.float() # or A.type(torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVlnWMiXAuqX",
        "outputId": "e9e826a1-b1d1-49b9-ba04-46d6ddc2d54c"
      },
      "outputs": [],
      "source": [
        "A.int() # or A.type(torch.int32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlVvVNPkkgy9"
      },
      "source": [
        "Note the missing dot (\".\") after tensor entries, indicating an integer dtype.\n",
        "\n",
        "The shapes of a tensor can be accessed via the `shape` property:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApZD22t5lC6-",
        "outputId": "28eb65e9-4909-4256-fff8-0e714acb0e8a"
      },
      "outputs": [],
      "source": [
        "print(x.shape, A.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecNrkA85bHCn"
      },
      "source": [
        "## PyTorch Devices\n",
        "\n",
        "A tensor's data is stored on a `device`, such as your GPU memory or your machine's RAM if using CPU. You can display where a tensor is stored by calling `.device()` on it, and manually copy it to a different device by calling `.to()`. This can be important when calculating data on a GPU, but wanting to plot the results locally. You will often see this written in the short form `.cpu()` in conjunction with converting to a NumPy array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d24eKN4FfIEt",
        "outputId": "57e86f59-42a4-42cc-ee31-2541157fb6dc"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    torch.cuda.set_device(device)\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZspWIcuhi8i"
      },
      "source": [
        "By copying over all participating tensors to GPU, we can perform GPU-accelerated computations in PyTorch. Below, we perform a convolution on an image from the internet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "h1SSaA-0bwUV",
        "outputId": "078ee3b6-d372-435c-d6b7-aac257da6851"
      },
      "outputs": [],
      "source": [
        "from IPython.core.pylabtools import figsize\n",
        "# example of copying tensors to and from GPU\n",
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12,4))\n",
        "image = imageio.imread(\"https://upload.wikimedia.org/wikipedia/commons/thumb\"+\n",
        "                       \"/5/50/STS41B-35-1613_-_Bruce_McCandless\"+\n",
        "                       \"_II_during_EVA_%28Retouched%29.jpg/1920px-STS41B-35-1613_-_Bruce_McCandless_II_during_EVA_%28Retouched%29.jpg\")\n",
        "ax1.imshow(image)\n",
        "\n",
        "# we'll make up a convolutional filter for this example\n",
        "filter = torch.linspace(-1,1, steps=5).repeat(5, 1)\n",
        "ax2.imshow(filter.numpy(), cmap='gray')\n",
        "\n",
        "# transform both tensors into expected shapes and dtypes:\n",
        "# `torch.conv2d` expects \"B Ci Hi Wi\" for the input and \"Co Ci Hk Wk\" for the kernel\n",
        "conv_kernel = filter.expand(1, 3, 5, 5).float()\n",
        "torch_image = torch.tensor([image]).permute(0,3,1,2).float()\n",
        "\n",
        "# note explicit copying to GPU (`.to(device)`)\n",
        "torch_result = torch.conv2d(torch_image.to(device), conv_kernel.to(device))\n",
        "print(torch_result.shape)\n",
        "# note copying back to CPU (`.cpu()`)\n",
        "numpy_result = torch_result.cpu()[0][0].numpy()\n",
        "ax3.imshow(numpy_result, cmap='gray')\n",
        "\n",
        "print(f\"Tensor torch_result is stored on device: {torch_result.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yajR2OuisPtH"
      },
      "source": [
        "Accessing the GPU tensor's memory directly from your python code with runs on your CPU will throw:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQjl4G0UdMKo",
        "outputId": "b9f9eb11-e1c1-4934-a5fb-0112def4ca6b"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    ax3.imshow(torch_result[0][0], cmap='Greys')\n",
        "except TypeError as error:\n",
        "    print(\"As expected direct access doesn't work:\", error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmDDYIxflLeF"
      },
      "source": [
        "## Tensor Products & Einsum Notation\n",
        "\n",
        "We will regularly need to compute a variety of vector products with tensors. While PyTorch has conventional functions for matrix-vector and matrix-matrix products, we encourage you to use the `einsum` function from `einops`. **However, if you're finding that using `einsum` is too time-consuming, you're free to use the regular matrix multiplication operator `@` instead. All of the homeworks can be completed using `@` instead of `einsum`.**\n",
        "\n",
        "The `einsum` function has the following signature:\n",
        "\n",
        "```python\n",
        "einsum(*tensors, pattern)\n",
        "```\n",
        "\n",
        "The pattern describes the operation `einsum` performs. The pattern consists of comma-separated input tensor shapes, which are each represented by a set of whitespace-separated dimensions; an arrow (`->`); and an output tensor shape, which is also represented by whitespace-separated dimensions. Here's an example:\n",
        "\n",
        "```python\n",
        "\"i j, j k -> i k\"\n",
        "```\n",
        "\n",
        "The pattern can also have longer names. For example, this pattern would be equivalent:\n",
        "\n",
        "```python\n",
        "\"apple orange, orange banana -> apple banana\"\n",
        "```\n",
        "\n",
        "The left side of the arrow names the axes of all of the input tensors. Tensors are comma-separated, and axes are whitespace-separated. In the above case, the input tensors each have two axes.\n",
        "\n",
        "The right side of the arrow names the axes that remain in the output tensor. All axes that are missing have been contracted via a dot product. In this case, the axis `j` (a.k.a. `orange`) appears in the two input vectors, but not on the right-hand side, which means that we contracted (i.e., dot-multiplied) the columns of the first tensor with the rows of the second tensor.\n",
        "\n",
        "It's easiest to learn `einsum` syntax through examples. Here are some examples:\n",
        "\n",
        "### Matrix-matrix Multiplication\n",
        "\n",
        "This is one extremely common use case. For example, it appears when applying a transformation to a camera extrinsics matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMFUr4hVLMW_"
      },
      "outputs": [],
      "source": [
        "a = torch.randn((3, 4))\n",
        "b = torch.randn((4, 5))\n",
        "\n",
        "assert torch.allclose(\n",
        "    a @ b,\n",
        "    einsum(a, b, \"i j, j k -> i k\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqIy89oV0281"
      },
      "source": [
        "### Batched Matrix-matrix Multiplication\n",
        "\n",
        "`einsum` supports arbitrary batch axes with ellipses (`...`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dunfq1tB0_PE"
      },
      "outputs": [],
      "source": [
        "a = torch.randn((128, 3, 4))\n",
        "b = torch.randn((128, 4, 5))\n",
        "\n",
        "# Expect an arbitrary number of batch dimensions (including none).\n",
        "assert torch.allclose(\n",
        "    a @ b,\n",
        "    einsum(a, b, \"... i j, ... j k -> ... i k\"),\n",
        ")\n",
        "\n",
        "# Expect a single batch dimension.\n",
        "assert torch.allclose(\n",
        "    a @ b,\n",
        "    einsum(a, b, \"batch i j, batch j k -> batch i k\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pkw2BtJrNw61"
      },
      "source": [
        "### Matrix-vector Multiplication\n",
        "\n",
        "This is another extremely common use case. For example, it appears when applying a transformation to a point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpfheiAxlKq7"
      },
      "outputs": [],
      "source": [
        "a = torch.randn((3, 4))\n",
        "b = torch.randn((4,))\n",
        "\n",
        "assert torch.allclose(\n",
        "    a @ b,\n",
        "    einsum(a, b, \"i j, j -> i\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X3M_cZL1iAM"
      },
      "source": [
        "### Batched Matrix-vector Multiplication\n",
        "\n",
        "Batched matrix-vector multiplication with the regular matrix multiplication operator `@` is annoying because an $n$-dimensional vector has to be converted to shape $(n, 1)$ before multiplication. `einsum` avoids this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tkw4ewl1vwb"
      },
      "outputs": [],
      "source": [
        "a = torch.randn((128, 3, 4))\n",
        "b = torch.randn((128, 4))\n",
        "\n",
        "assert torch.allclose(\n",
        "    (a @ b[..., None])[..., 0],\n",
        "    einsum(a, b, \"... i j, ... j -> ... i\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pFjUGEy16qD"
      },
      "source": [
        "### Matrix-matrix Multiplication with Transpose\n",
        "\n",
        "`einsum` makes it easy to transpose and matrix-multiply at the same time. Named axes (e.g., using `h`, `w`, `c`, and `b` to mean \"height,\" \"width,\" \"channel,\" and \"batch\") make it clear what's happening."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BilvYRFWEMi"
      },
      "outputs": [],
      "source": [
        "a = torch.randn((5, 5, 4, 5))\n",
        "b = torch.randn((4, 2))\n",
        "\n",
        "assert torch.allclose(\n",
        "    (a.permute((0, 1, 3, 2)) @ b).permute((0, 1, 3, 2)),\n",
        "    einsum(a, b, \"h w c b, c f -> h w f b\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_qJP5qQBpd8"
      },
      "source": [
        "### More Than Two Inputs\n",
        "\n",
        "`einsum` can have more than two inputs. For example, one could evaluate $x^T \\Sigma x$, where $x$ is a (possibly batched) vector and $\\Sigma$ is a (possibly batched) square matrix, as follows. Note how `einsum` makes it easy to handle the batch dimension in `x`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iuF6Tz4B2X8"
      },
      "outputs": [],
      "source": [
        "x = torch.randn((64, 3))\n",
        "covariance = torch.eye(3)\n",
        "\n",
        "assert torch.allclose(\n",
        "    (x[:, None] @ covariance @ x[..., None])[..., 0, 0],\n",
        "    einsum(x, covariance, x, \"... i, ... i j, ... j -> ...\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g32Ts2qUNs_",
        "outputId": "34dc0400-4685-435c-b687-5160244175bd"
      },
      "outputs": [],
      "source": [
        "a = np.array([[1, 2, 3], [4, 5, 6], [3,4,7]])\n",
        "b = np.array([10, 20, 30])\n",
        "\n",
        "# Adding a new axis to array b\n",
        "b_new = b[:,None]\n",
        "print(\"Array a:\")\n",
        "print(a)\n",
        "\n",
        "print(\"\\nArray b with a new axis:\")\n",
        "print(b_new)\n",
        "\n",
        "# Broadcasting addition\n",
        "result = a + b_new\n",
        "\n",
        "print(\"\\nResult of broadcasting addition:\")\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmKR9eJcm0id"
      },
      "source": [
        "## Batching & broadcasting\n",
        "\n",
        "We usually want to write batched code. This means that we generally expect our tensors to have one or more leading batch dimensions. Assume, for instance, that our dataset consists of *many point clouds*, each of which has 1000 3-dimensional points. A *batch of point clouds* would then be a tensor of shape (batch_size, num_points, 3):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1eXSMgem438",
        "outputId": "7d97b06b-e9da-4172-9890-dd706695d90b"
      },
      "outputs": [],
      "source": [
        "batch_size = 10\n",
        "num_points = 1000\n",
        "pc_batch = torch.zeros((batch_size, num_points, 3)).float()\n",
        "print(pc_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nbaUFGDnSts"
      },
      "source": [
        "If we wanted to multiply *all* the point clouds in this batch with the matrix $A \\in \\mathbb{R}^{3\\times3}$, einsum makes this easy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb032uJ4nfAk",
        "outputId": "9f78cb68-31a0-4fa8-9987-6a3a30580723"
      },
      "outputs": [],
      "source": [
        "A = torch.randn((3, 3))\n",
        "\n",
        "pc_batch_transformed = einsum(pc_batch, A, \"b n j, i j -> b n i\")\n",
        "print(pc_batch_transformed.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyDdooBaspvc"
      },
      "source": [
        "Recall that `einsum` supports also supports arbitrary/multiple batch dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSEw1yzuswvy",
        "outputId": "35e4dd28-561d-4e90-b765-aa76d2aa5a3f"
      },
      "outputs": [],
      "source": [
        "A = torch.randn((3, 3))\n",
        "\n",
        "pc_batch_transformed = einsum(pc_batch, A, \"... n j, i j -> ... n i\")\n",
        "print(pc_batch_transformed.shape)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
